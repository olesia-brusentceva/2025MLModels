{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83f6ab7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import fsolve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ae8b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability of a point being white (k=0) if x1 >= 0\n",
    "P_WHITE_IF_X1_GE_0 = 0.7  # denoted as 'p' in the problem description\n",
    "# Probability of a point being white (k=0) if x1 < 0\n",
    "P_WHITE_IF_X1_LT_0 = 0.3  # denoted as 'q' in the problem description\n",
    "# Probability that the VC bound does NOT hold (epsilon-net probability)\n",
    "ETA = 0.05                # denoted as 'η'\n",
    "# Maximum allowed absolute difference between theoretical and empirical risks\n",
    "EPSILON = 0.1             # denoted as 'ε'\n",
    "# Size of the new sample for testing the chosen strategy\n",
    "N_TEST_SAMPLE = 1000      # denoted as 'N'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ee3ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Task 1: Calculate Vapnik-Chervonenkis (VC) Dimension\n",
    "def calculate_vc_dimension():\n",
    "    \"\"\"\n",
    "    Calculates the Vapnik-Chervonenkis (VC) dimension for the given set of strategies.\n",
    "    The strategies are linear classifiers in R^2, defined by (x.a) >= theta or (x.a) < theta.\n",
    "    For linear classifiers in a d-dimensional space, the VC dimension is d+1.\n",
    "    Here, the input space is R^2, so d=2.\n",
    "    \"\"\"\n",
    "    vc_dim = 2 + 1\n",
    "    return vc_dim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6146550",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Task 2: Estimate Training Sample Size (l)\n",
    "def estimate_sample_size(vc_dim, epsilon, eta):\n",
    "    \"\"\"\n",
    "    Estimates the minimum training sample size 'l' required such that with probability\n",
    "    1 - eta, the absolute difference (modulo) between theoretical and empirical risks\n",
    "    for all admissible strategies does not exceed epsilon.\n",
    "\n",
    "    This estimation uses the Vapnik-Chervonenkis bound:\n",
    "    epsilon >= sqrt( (8/l) * ( VC_dim * ln(2l/VC_dim) + ln(4/eta) ) )\n",
    "\n",
    "    Since this is a transcendental equation for 'l', it is solved numerically using fsolve.\n",
    "    \"\"\"\n",
    "    # Define the function for which we want to find the root (f(l) = 0)\n",
    "    def vc_bound_equation(l_val):\n",
    "        # Ensure l_val and vc_dim are positive to avoid math domain errors (log of non-positive)\n",
    "        if l_val <= 0 or vc_dim <= 0:\n",
    "            # Return a large positive value to push the solver towards positive l\n",
    "            return float('inf')\n",
    "        \n",
    "        # Calculate the terms inside the square root\n",
    "        term_vc_log = vc_dim * math.log(2 * l_val / vc_dim)\n",
    "        term_eta_log = math.log(4 / eta)\n",
    "        \n",
    "        # The equation we want to solve for l: sqrt(...) - epsilon = 0\n",
    "        return math.sqrt((8 / l_val) * (term_vc_log + term_eta_log)) - epsilon\n",
    "\n",
    "    # Provide an initial guess for 'l'. A heuristic based on simpler bounds (l ~ VC_dim / epsilon^2)\n",
    "    # can help fsolve converge. We multiply by 10 to give a slightly larger starting point.\n",
    "    initial_guess = vc_dim / (epsilon**2) * 10 \n",
    "    \n",
    "    # Use fsolve to find the root. fsolve returns an array, so we take the first element.\n",
    "    l_estimated = fsolve(vc_bound_equation, initial_guess)[0]\n",
    "\n",
    "    # The sample size must be a positive integer. We take the ceiling and ensure it's at least 1.\n",
    "    return math.ceil(max(1, l_estimated))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7976cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Task 3: Generate Sample, Choose Strategy, Test Strategy ---\n",
    "\n",
    "def generate_data(num_samples, p_white_x1_ge_0, p_white_x1_lt_0):\n",
    "    \"\"\"\n",
    "    Generates a dataset of 2D points (x1, x2) and their corresponding labels.\n",
    "    Points are generated from a standard normal distribution N((0,0), I).\n",
    "    Labels are assigned based on x1 and the probabilities p and q.\n",
    "    Label k=0 for white, k=1 for black.\n",
    "    \"\"\"\n",
    "    # Generate points from a 2D standard normal distribution\n",
    "    points = np.random.multivariate_normal([0, 0], [[1, 0], [0, 1]], num_samples)\n",
    "    labels = np.zeros(num_samples, dtype=int) # Initialize labels array\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        x1 = points[i, 0]\n",
    "        \n",
    "        # Assign label based on x1 value and probabilities p or q\n",
    "        if x1 >= 0:\n",
    "            # If x1 >= 0, label is white (0) with probability p, black (1) with probability 1-p\n",
    "            if np.random.rand() < p_white_x1_ge_0:\n",
    "                labels[i] = 0  # White\n",
    "            else:\n",
    "                labels[i] = 1  # Black\n",
    "        else:\n",
    "            # If x1 < 0, label is white (0) with probability q, black (1) with probability 1-q\n",
    "            if np.random.rand() < p_white_x1_lt_0:\n",
    "                labels[i] = 0  # White\n",
    "            else:\n",
    "                labels[i] = 1  # Black\n",
    "\n",
    "    return points, labels\n",
    "\n",
    "def main():\n",
    "  \n",
    "    print(\"--- Recognition by Training Sample ---\")\n",
    "\n",
    "    # --- Task 1 Execution ---\n",
    "    print(\"\\n--- Task 1: VC Dimension Calculation ---\")\n",
    "    vc_dimension = calculate_vc_dimension()\n",
    "    print(f\"The Vapnik-Chervonenkis (VC) dimension of the given set of strategies is: {vc_dimension}\")\n",
    "\n",
    "    # --- Task 2 Execution ---\n",
    "    print(\"\\n--- Task 2: Training Sample Size Estimation ---\")\n",
    "    # Validate ETA and EPSILON parameters\n",
    "    if not (0 < ETA < 1 and 0 < EPSILON < 1):\n",
    "        print(\"Error: ETA and EPSILON must be strictly between 0 and 1. Please adjust parameters.\")\n",
    "\n",
    "\n",
    "    training_sample_size = estimate_sample_size(vc_dimension, EPSILON, ETA)\n",
    "    print(f\"To ensure that with probability 1 - {ETA}, the absolute difference between theoretical\")\n",
    "    print(f\"and empirical risks does not exceed {EPSILON}, the estimated minimum training sample size (l) is: {training_sample_size}\")\n",
    "    print(\"(Note: This is a numerical estimate based on the VC bound, and may result in a large 'l'.)\")\n",
    "\n",
    "\n",
    "    # --- Task 3 Execution ---\n",
    "    print(\"\\n--- Task 3: Strategy Generation and Testing ---\")\n",
    "    print(f\"Current Parameters for Task 3:\")\n",
    "    print(f\"  p (P_WHITE_IF_X1_GE_0) = {P_WHITE_IF_X1_GE_0}\")\n",
    "    print(f\"  q (P_WHITE_IF_X1_LT_0) = {P_WHITE_IF_X1_LT_0}\")\n",
    "    print(f\"  N (test sample size) = {N_TEST_SAMPLE}\")\n",
    "\n",
    "    # 3.1 Generate training sample\n",
    "    print(f\"\\nGenerating training sample of size {training_sample_size}...\")\n",
    "    X_train, y_train = generate_data(training_sample_size, P_WHITE_IF_X1_GE_0, P_WHITE_IF_X1_LT_0)\n",
    "    print(\"Training sample generated.\")\n",
    "    \n",
    "    print(\"Training Logistic Regression model to find optimal strategy...\")\n",
    "    model = LogisticRegression(solver='liblinear', random_state=42) # liblinear is good for small datasets\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    optimal_a = model.coef_[0]\n",
    "    optimal_theta = -model.intercept_[0]\n",
    "\n",
    "    print(f\"Optimal strategy found: a = {optimal_a}, theta = {optimal_theta:.4f}\")\n",
    "\n",
    "    # Define the chosen strategy function using the derived 'a' and 'theta'\n",
    "    def chosen_strategy(x_point, a_vec, theta_val):\n",
    "        \"\"\"Applies the chosen linear classification strategy to a single point.\"\"\"\n",
    "        return 0 if np.dot(x_point, a_vec) >= theta_val else 1\n",
    "\n",
    "    # Calculate empirical risk on the training sample using the chosen strategy\n",
    "    train_predictions = np.array([chosen_strategy(x, optimal_a, optimal_theta) for x in X_train])\n",
    "    empirical_risk_train = np.mean(train_predictions != y_train)\n",
    "    print(f\"Empirical risk on training sample: {empirical_risk_train:.4f}\")\n",
    "\n",
    "    # 3.3 Test the chosen strategy on a new sample\n",
    "    print(f\"\\nGenerating new test sample of size {N_TEST_SAMPLE}...\")\n",
    "    X_test, y_test = generate_data(N_TEST_SAMPLE, P_WHITE_IF_X1_GE_0, P_WHITE_IF_X1_LT_0)\n",
    "    print(\"Test sample generated.\")\n",
    "\n",
    "    test_predictions = np.array([chosen_strategy(x, optimal_a, optimal_theta) for x in X_test])\n",
    "    empirical_risk_test = np.mean(test_predictions != y_test)\n",
    "    print(f\"Empirical risk on test sample: {empirical_risk_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9099702e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Recognition by Training Sample ---\n",
      "\n",
      "--- Task 1: VC Dimension Calculation ---\n",
      "The Vapnik-Chervonenkis (VC) dimension of the given set of strategies is: 3\n",
      "\n",
      "--- Task 2: Training Sample Size Estimation ---\n",
      "To ensure that with probability 1 - 0.05, the absolute difference between theoretical\n",
      "and empirical risks does not exceed 0.1, the estimated minimum training sample size (l) is: 27024\n",
      "(Note: This is a numerical estimate based on the VC bound, and may result in a large 'l'.)\n",
      "\n",
      "--- Task 3: Strategy Generation and Testing ---\n",
      "Current Parameters for Task 3:\n",
      "  p (P_WHITE_IF_X1_GE_0) = 0.7\n",
      "  q (P_WHITE_IF_X1_LT_0) = 0.3\n",
      "  N (test sample size) = 1000\n",
      "\n",
      "Generating training sample of size 27024...\n",
      "Training sample generated.\n",
      "Training Logistic Regression model to find optimal strategy...\n",
      "Optimal strategy found: a = [-0.70959334  0.0139563 ], theta = -0.0182\n",
      "Empirical risk on training sample: 0.6991\n",
      "\n",
      "Generating new test sample of size 1000...\n",
      "Test sample generated.\n",
      "Empirical risk on test sample: 0.7260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OlesiaBrusentseva\\AppData\\Local\\Temp\\ipykernel_12060\\2455665693.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  term_vc_log = vc_dim * math.log(2 * l_val / vc_dim)\n",
      "C:\\Users\\OlesiaBrusentseva\\AppData\\Local\\Temp\\ipykernel_12060\\2455665693.py:25: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  return math.sqrt((8 / l_val) * (term_vc_log + term_eta_log)) - epsilon\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Entry point for the script execution\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac480284",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
