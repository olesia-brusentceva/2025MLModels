{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, models, transforms\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data for CV modeling. \n",
    "\n",
    "Data: \"Cassava Leaf Disease Classification\"\n",
    "\n",
    "21 367 images 5 classes\n",
    "\n",
    "Unbalanced classes, natural noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/nirmalsankalana/cassava-leaf-disease-classification?dataset_version_number=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2.39G/2.39G [11:25<00:00, 3.74MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\OlesiaBrusentseva\\.cache\\kagglehub\\datasets\\nirmalsankalana\\cassava-leaf-disease-classification\\versions\\2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"nirmalsankalana/cassava-leaf-disease-classification\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1fa78b1cd30>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ───────────────────────────  Config & Paths  ─────────────────────────\n",
    "DATA_DIR       = Path(\"dataLab1\")   # root folder with 5 sub-folders\n",
    "BATCH_SIZE     = 32\n",
    "NUM_WORKERS    = os.cpu_count() or 2\n",
    "NUM_EPOCHS     = 5                         # quick demo – increase if GPU budget allows\n",
    "VAL_SPLIT      = 0.20\n",
    "SEED           = 42\n",
    "DEVICE         = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "BATCH_SIZE = 32\n",
    "TRAIN_SPLIT = 0.7 # 70% for training\n",
    "VALIDATION_SPLIT = 0.15 # 15% for validation\n",
    "TEST_SPLIT = 0.15 # 15% for testing\n",
    "SEED = 42 # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ────────────────────────  Data & Transforms  ─────────────────────────\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225]),\n",
    "])\n",
    "val_tfms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "full_ds = datasets.ImageFolder(DATA_DIR, transform=train_tfms)\n",
    "num_classes = len(full_ds.classes)\n",
    "\n",
    "# Custom split (train/val) so the same images aren’t reused.\n",
    "val_len = int(len(full_ds) * VAL_SPLIT)\n",
    "train_len = len(full_ds) - val_len\n",
    "train_ds, val_ds = random_split(full_ds, [train_len, val_len],\n",
    "                                generator=torch.Generator().manual_seed(SEED))\n",
    "# Validation uses deterministic transforms\n",
    "val_ds.dataset.transform = val_tfms\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE,\n",
    "                          shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE,\n",
    "                          shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ────────────────────────  Helper Functions  ──────────────────────────\n",
    "def train_one_epoch(model: nn.Module, loader: DataLoader,\n",
    "                    criterion, optimizer) -> float:\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    for inputs, labels in loader:\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total   += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model: nn.Module, loader: DataLoader, criterion) -> Tuple[float, float]:\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "    for inputs, labels in loader:\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = outputs.max(1)\n",
    "        correct    += (preds == labels).sum().item()\n",
    "        total      += labels.size(0)\n",
    "        all_preds.extend(preds.cpu().tolist())\n",
    "        all_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "    report = classification_report(all_labels, all_preds,\n",
    "                                   target_names=full_ds.classes,\n",
    "                                   digits=3, zero_division=0)\n",
    "    return running_loss / total, correct / total, report\n",
    "\n",
    "def run_training(model, epochs=NUM_EPOCHS):\n",
    "    model.to(DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.3)\n",
    "\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        t0 = time.time()\n",
    "        tr_loss, tr_acc = train_one_epoch(model, train_loader, criterion, optimizer)\n",
    "        vl_loss, vl_acc, _ = evaluate(model, val_loader, criterion)\n",
    "        scheduler.step()\n",
    "\n",
    "        if vl_acc > best_acc:\n",
    "            best_acc = vl_acc\n",
    "            best_wts = model.state_dict()\n",
    "\n",
    "        print(f\"[{epoch:02}/{epochs}] \"\n",
    "              f\"Train loss={tr_loss:.4f} acc={tr_acc:.3f} | \"\n",
    "              f\"Val loss={vl_loss:.4f} acc={vl_acc:.3f} \"\n",
    "              f\"({time.time() - t0:.1f}s)\")\n",
    "\n",
    "    model.load_state_dict(best_wts)\n",
    "    _, _, final_report = evaluate(model, val_loader, criterion)\n",
    "    print(\"\\nBest validation accuracy: {:.3f}\".format(best_acc))\n",
    "    print(final_report)\n",
    "    return best_acc, final_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "─────────  Baseline (training from scratch)  ─────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OlesiaBrusentseva\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01/5] Train loss=1.0611 acc=0.626 | Val loss=0.9641 acc=0.636 (959.5s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OlesiaBrusentseva\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/5] Train loss=0.9499 acc=0.647 | Val loss=0.8964 acc=0.670 (974.5s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OlesiaBrusentseva\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/5] Train loss=0.9017 acc=0.662 | Val loss=0.8681 acc=0.678 (955.8s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OlesiaBrusentseva\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04/5] Train loss=0.8318 acc=0.686 | Val loss=0.7929 acc=0.694 (948.8s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OlesiaBrusentseva\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05/5] Train loss=0.7988 acc=0.699 | Val loss=0.7532 acc=0.711 (946.9s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OlesiaBrusentseva\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best validation accuracy: 0.711\n",
      "                                precision    recall  f1-score   support\n",
      "\n",
      "    Cassava___bacterial_blight      0.394     0.179     0.246       207\n",
      "Cassava___brown_streak_disease      0.576     0.322     0.413       401\n",
      "        Cassava___green_mottle      0.660     0.127     0.214       502\n",
      "             Cassava___healthy      0.437     0.579     0.498       539\n",
      "      Cassava___mosaic_disease      0.794     0.951     0.866      2630\n",
      "\n",
      "                      accuracy                          0.711      4279\n",
      "                     macro avg      0.572     0.432     0.447      4279\n",
      "                  weighted avg      0.694     0.711     0.670      4279\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ────────────────────────────  Baseline CNN  ──────────────────────────\n",
    "class SmallCNN(nn.Module):\n",
    "    \"\"\"A lightweight CNN built from scratch – serves as the baseline.\"\"\"\n",
    "    def __init__(self, n_classes: int):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(128, 256, 3, padding=1), nn.ReLU(), nn.AdaptiveAvgPool2d(1),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x).flatten(1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "print(\"\\n─────────  Baseline (training from scratch)  ─────────\")\n",
    "baseline_model = SmallCNN(num_classes)\n",
    "baseline_acc, baseline_report = run_training(baseline_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "─────────  Fine-tuning EfficientNet-B0  ─────────\n",
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to C:\\Users\\OlesiaBrusentseva/.cache\\torch\\hub\\checkpoints\\efficientnet_b0_rwightman-7f5810bc.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20.5M/20.5M [00:03<00:00, 6.05MB/s]\n",
      "C:\\Users\\OlesiaBrusentseva\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01/5] Train loss=0.6153 acc=0.781 | Val loss=0.5471 acc=0.823 (2104.3s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OlesiaBrusentseva\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/5] Train loss=0.4669 acc=0.840 | Val loss=0.4537 acc=0.845 (2159.6s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OlesiaBrusentseva\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/5] Train loss=0.3925 acc=0.866 | Val loss=0.4374 acc=0.852 (2259.7s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OlesiaBrusentseva\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04/5] Train loss=0.2347 acc=0.921 | Val loss=0.4238 acc=0.860 (2178.9s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OlesiaBrusentseva\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05/5] Train loss=0.1430 acc=0.951 | Val loss=0.4914 acc=0.856 (2096.0s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OlesiaBrusentseva\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best validation accuracy: 0.860\n",
      "                                precision    recall  f1-score   support\n",
      "\n",
      "    Cassava___bacterial_blight      0.598     0.488     0.537       207\n",
      "Cassava___brown_streak_disease      0.681     0.810     0.740       401\n",
      "        Cassava___green_mottle      0.818     0.743     0.779       502\n",
      "             Cassava___healthy      0.680     0.653     0.666       539\n",
      "      Cassava___mosaic_disease      0.944     0.954     0.949      2630\n",
      "\n",
      "                      accuracy                          0.856      4279\n",
      "                     macro avg      0.744     0.730     0.734      4279\n",
      "                  weighted avg      0.855     0.856     0.854      4279\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ─────────────────────────  Fine-Tuned Model  ─────────────────────────\n",
    "print(\"\\n─────────  Fine-tuning EfficientNet-B0  ─────────\")\n",
    "ft_model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "ft_model.classifier[1] = nn.Linear(ft_model.classifier[1].in_features, num_classes)\n",
    "# Option A: fine-tune *all* layers\n",
    "for p in ft_model.parameters():\n",
    "    p.requires_grad = True\n",
    "fine_tune_acc, fine_tune_report = run_training(ft_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━  Summary  ━━━━━━━━━━━━━━━━\n",
      "Baseline accuracy:    71.14 %\n",
      "Fine-tuned accuracy:  85.98 %\n",
      "\n",
      "Baseline confusion / precision / recall:\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "    Cassava___bacterial_blight      0.394     0.179     0.246       207\n",
      "Cassava___brown_streak_disease      0.576     0.322     0.413       401\n",
      "        Cassava___green_mottle      0.660     0.127     0.214       502\n",
      "             Cassava___healthy      0.437     0.579     0.498       539\n",
      "      Cassava___mosaic_disease      0.794     0.951     0.866      2630\n",
      "\n",
      "                      accuracy                          0.711      4279\n",
      "                     macro avg      0.572     0.432     0.447      4279\n",
      "                  weighted avg      0.694     0.711     0.670      4279\n",
      "\n",
      "\n",
      "Fine-tuned confusion / precision / recall:\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "    Cassava___bacterial_blight      0.598     0.488     0.537       207\n",
      "Cassava___brown_streak_disease      0.681     0.810     0.740       401\n",
      "        Cassava___green_mottle      0.818     0.743     0.779       502\n",
      "             Cassava___healthy      0.680     0.653     0.666       539\n",
      "      Cassava___mosaic_disease      0.944     0.954     0.949      2630\n",
      "\n",
      "                      accuracy                          0.856      4279\n",
      "                     macro avg      0.744     0.730     0.734      4279\n",
      "                  weighted avg      0.855     0.856     0.854      4279\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ───────────────────────────  Comparison  ─────────────────────────────\n",
    "print(\"━━━━━━━━━━━━━━━━  Summary  ━━━━━━━━━━━━━━━━\")\n",
    "print(f\"Baseline accuracy:    {baseline_acc*100:.2f} %\")\n",
    "print(f\"Fine-tuned accuracy:  {fine_tune_acc*100:.2f} %\")\n",
    "print(\"\\nBaseline confusion / precision / recall:\\n\", baseline_report)\n",
    "print(\"\\nFine-tuned confusion / precision / recall:\\n\", fine_tune_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
